{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyucL1q0VrzE9asaMvzFAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a81Biz/ChatBot/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiLbgRlIpS9B",
        "outputId": "59308b89-c10c-4cd7-fa23-b0fa5d63d96d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.6.8)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.5.7)\n",
            "Requirement already satisfied: langchain>=0.0.154 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.0.171)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.27.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: requests<2.30.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.27.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (4.0.2)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (1.10.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<2.30.0->llama-index) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<2.30.0->llama-index) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<2.30.0->llama-index) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<2.30.0->llama-index) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain>=0.0.154->llama-index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.154->llama-index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "idfD8lQ9oDee"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from llama_index import download_loader, GPTVectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
        "from pathlib import Path\n",
        "from llama_index import GPTListIndex, LLMPredictor\n",
        "from langchain import OpenAI\n",
        "from llama_index.indices.composability import ComposableGraph\n",
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from llama_index.langchain_helpers.agents import LlamaToolkit, create_llama_chat_agent, IndexToolConfig\n",
        "\n",
        "# define a decompose transform\n",
        "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
        "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de la carpeta de origen\n",
        "ruta_docs = './docs'\n",
        "\n",
        "# Ruta de la carpeta de destino\n",
        "ruta_chatDocs = './chatDocs'\n",
        "\n",
        "# Verificar si la carpeta de destino existe, y si no, crearla\n",
        "if not os.path.exists(ruta_chatDocs):\n",
        "    os.makedirs(ruta_chatDocs)\n",
        "\n",
        "# Lista para almacenar los nombres y extensiones de los documentos\n",
        "nombres_documentos = []\n",
        "\n",
        "# Recorrer los archivos de la carpeta de origen\n",
        "for archivo in os.listdir(ruta_docs):\n",
        "    # Obtener la ruta completa del archivo de origen\n",
        "    ruta_origen = os.path.join(ruta_docs, archivo)\n",
        "\n",
        "    # Verificar si es un archivo (no directorio)\n",
        "    if os.path.isfile(ruta_origen):\n",
        "        # Obtener el nuevo nombre del archivo en minúsculas y sin espacios\n",
        "        nuevo_nombre = archivo.lower().replace(' ', '')\n",
        "\n",
        "        # Obtener la ruta completa del archivo de destino\n",
        "        ruta_destino = os.path.join(ruta_chatDocs, nuevo_nombre)\n",
        "\n",
        "        # Copiar el archivo a la carpeta de destino\n",
        "        shutil.copyfile(ruta_origen, ruta_destino)\n",
        "\n",
        "        # Obtener el nombre y extensión del archivo y agregarlo a la lista\n",
        "        nombre, extension = os.path.splitext(nuevo_nombre)\n",
        "        nombres_documentos.append((nombre, extension))"
      ],
      "metadata": {
        "id": "KPCdV1tfoM2c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_set = {}\n",
        "all_docs = []\n",
        "for nombre, extension  in nombres_documentos:\n",
        "    each_docs = SimpleDirectoryReader(f'{ruta_chatDocs}/{nombre}{extension}').load_data()\n",
        "    # insert year metadata into each year\n",
        "    for d in each_docs:\n",
        "        d.extra_info = {\"doc\": nombre}\n",
        "    doc_set[nombre] = each_docs\n",
        "    all_docs.extend(each_docs)"
      ],
      "metadata": {
        "id": "eUAVnaCOojZA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#key de API OpenAi\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'xxx'"
      ],
      "metadata": {
        "id": "FiqyWGnwosly"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize simple vector indices + global vector index\n",
        "# NOTE: don't run this cell if the indices are already loaded! \n",
        "cur_index = {}\n",
        "index_set = {}\n",
        "service_context = ServiceContext.from_defaults(chunk_size_limit=512)\n",
        "for nombre, extension in nombres_documentos:\n",
        "    cur_index = GPTVectorStoreIndex.from_documents(doc_set[nombre])\n",
        "    index_set[nombre] = cur_index\n"
      ],
      "metadata": {
        "id": "MqOl9eH_ovvj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load indices from disk\n",
        "for nombre in nombres_documentos:\n",
        "    index_set[nombre] = cur_index"
      ],
      "metadata": {
        "id": "VrO3e_TyowVD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set summary text for each doc\n",
        "index_summaries = [f\"Indices de {nombre}\" for nombre in nombres_documentos]\n"
      ],
      "metadata": {
        "id": "vG85O34Iox9Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set number of output tokens\n",
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, max_tokens=512))\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)"
      ],
      "metadata": {
        "id": "kFoP9SXSo07V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a list index over the vector indices\n",
        "# allows us to synthesize information across each index\n",
        "graph = ComposableGraph.from_indices(\n",
        "    GPTListIndex, \n",
        "    [index_set[n] for n, e in nombres_documentos], \n",
        "    index_summaries=index_summaries,\n",
        "    service_context=service_context\n",
        ")"
      ],
      "metadata": {
        "id": "UDgAGwllo3I5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decompose_transform = DecomposeQueryTransform(\n",
        "    llm_predictor, verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "QLjkk0ajo6aX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define custom query engines\n",
        "custom_query_engines = {}\n",
        "for index in index_set.values():\n",
        "    query_engine = index.as_query_engine()\n",
        "    query_engine = TransformQueryEngine(\n",
        "        query_engine,\n",
        "        query_transform=decompose_transform,\n",
        "        transform_extra_info={'index_summary': index.index_struct.summary},\n",
        "    )\n",
        "    custom_query_engines[index.index_id] = query_engine\n",
        "custom_query_engines[graph.root_id] = graph.root_index.as_query_engine(\n",
        "    response_mode='tree_summarize',\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "fBaZavfWo8fZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct query engine\n",
        "graph_query_engine = graph.as_query_engine(custom_query_engines=custom_query_engines)"
      ],
      "metadata": {
        "id": "bkhQViZdo-bj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index configs\n",
        "index_configs = []\n",
        "for nombre, ext in nombres_documentos:\n",
        "    query_engine = index_set[nombre].as_query_engine( \n",
        "        similarity_top_k=3, \n",
        "        )\n",
        "    tool_config = IndexToolConfig(\n",
        "        query_engine=query_engine, \n",
        "        name=f\"Vector Index {nombre}\",\n",
        "        description=f\"useful for when you want to answer queries about the {nombre} \",\n",
        "        tool_kwargs={\"return_direct\": True, \"return_sources\": True},\n",
        "    )\n",
        "    index_configs.append(tool_config)"
      ],
      "metadata": {
        "id": "Ti624XDNpAZ3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graph config\n",
        "graph_config = IndexToolConfig(\n",
        "    query_engine=graph_query_engine,\n",
        "    name=f\"Graph Index\",\n",
        "    description=\"useful for when you want to answer queries that require analyzing multiple  documents.\",\n",
        "    tool_kwargs={\"return_direct\": True, \"return_sources\": True},\n",
        "    return_sources=True\n",
        ")\n",
        "\n",
        "toolkit = LlamaToolkit(\n",
        "    index_configs=index_configs,\n",
        "    graph_configs=[graph_config]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm=OpenAI(temperature=0)\n",
        "agent_chain = create_llama_chat_agent(\n",
        "    toolkit,\n",
        "    llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "1ATS8aihpEgW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    text_input = input(\"User: \")\n",
        "    response = agent_chain.run(input=text_input)\n",
        "    print(f'Agent: {response}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "vasHPjXHpFSc",
        "outputId": "ef9b221c-be05-4c66-9583-0deb1a0117c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What are the main needs and challenges of the support team in non-production environments?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "AI: The main needs and challenges of the support team in non-production environments include ensuring that the environment is stable and secure, providing timely and accurate support to users, and ensuring that the environment is up-to-date with the latest software and security patches. Additionally, the support team must be able to quickly identify and resolve any issues that arise in the environment.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent: The main needs and challenges of the support team in non-production environments include ensuring that the environment is stable and secure, providing timely and accurate support to users, and ensuring that the environment is up-to-date with the latest software and security patches. Additionally, the support team must be able to quickly identify and resolve any issues that arise in the environment.\n",
            "User: What servers have the CommonsMail library installed?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "AI: The Vector Index 04_guiadeusuarioserviciol2yl3 contains information about which servers have the CommonsMail library installed.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent: The Vector Index 04_guiadeusuarioserviciol2yl3 contains information about which servers have the CommonsMail library installed.\n",
            "User: ¿Cuáles son las categorías de tickets y sus respectivos SLA's por plataformas?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "AI: El Vector Index 05_stringconexiones_qa_xplataforma contiene información sobre las categorías de tickets y sus respectivos SLA's por plataformas.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent: El Vector Index 05_stringconexiones_qa_xplataforma contiene información sobre las categorías de tickets y sus respectivos SLA's por plataformas.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cc3812266c53>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Agent: {response}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}
